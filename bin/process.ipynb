{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_df = pd.read_excel(glob(\"CallSignSeriesRanges*.xlsx\")[0]).rename({\"Allocated to\": \"region\"}, axis=1)\n",
    "in_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_df[\"start0\"] = in_df[\"Series\"].apply(lambda x: x[0])\n",
    "in_df[\"start01\"] = in_df[\"Series\"].apply(lambda x: x[:2])\n",
    "in_df[\"start012\"] = in_df[\"Series\"].apply(lambda x: x[:3])\n",
    "in_df[\"stop0\"] = in_df[\"Series\"].apply(lambda x: x[6])\n",
    "in_df[\"stop01\"] = in_df[\"Series\"].apply(lambda x: x[6:8])\n",
    "in_df[\"stop012\"] = in_df[\"Series\"].apply(lambda x: x[6:9])\n",
    "\n",
    "in_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_df = pd.concat(\n",
    "    [in_df[[\"Series\", \"region\", \"start0\", \"start01\", \"start012\"]],\n",
    "    in_df[[\"Series\", \"region\", \"stop0\", \"stop01\", \"stop012\"]].rename({\n",
    "        \"stop0\": \"start0\",\n",
    "        \"stop01\": \"start01\",\n",
    "        \"stop012\": \"start012\"\n",
    "    }, axis=1)]\n",
    ")\n",
    "\n",
    "in_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check if the list of countries for the first position is unique\n",
    "## check if the list of countries for the first two positions is unique\n",
    "## check for the first three positions\n",
    "## i.e. anything beginning with 2 must be the UK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_first_pos_set = set(in_df[\"start0\"])\n",
    "first_round_dict = {}\n",
    "seen_starts_set = set()\n",
    "\n",
    "for x in unique_first_pos_set:\n",
    "    temp_df = in_df[in_df[\"start0\"] == x].drop_duplicates(\"region\")\n",
    "    if len(temp_df) == 1:\n",
    "        first_round_dict[x] = list(temp_df[\"region\"])[0]\n",
    "        seen_starts_set.add(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = in_df[~in_df[\"start0\"].isin(seen_starts_set)]\n",
    "\n",
    "unique_first_two_pos_set = set(sub_df[\"start01\"])\n",
    "second_round_dict = {}\n",
    "seen_starts_second_set = set()\n",
    "\n",
    "for x in unique_first_two_pos_set:\n",
    "    temp_df = sub_df[sub_df[\"start01\"] == x].drop_duplicates(\"region\")\n",
    "    if len(temp_df) == 1:\n",
    "        second_round_dict[x] = list(temp_df[\"region\"])[0]\n",
    "        seen_starts_second_set.add(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = sub_df[~sub_df[\"start01\"].isin(seen_starts_second_set)]\n",
    "\n",
    "unique_first_three_pos_set = set(sub_df[\"start012\"])\n",
    "third_round_dict = {}\n",
    "seen_starts_third_set = set()\n",
    "\n",
    "for x in unique_first_three_pos_set:\n",
    "    temp_df = sub_df[sub_df[\"start012\"] == x].drop_duplicates(\"region\")\n",
    "    if len(temp_df) == 1:\n",
    "        third_round_dict[x] = list(temp_df[\"region\"])[0]\n",
    "        seen_starts_third_set.add(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_round_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_round_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "third_round_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = sub_df[~sub_df[\"start01\"].isin(seen_starts_third_set)]\n",
    "\n",
    "sub_df = sub_df.drop_duplicates([\"Series\", \"region\"]).drop([\"start0\", \"start01\", \"start012\"], axis=1)\n",
    "\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_into_regex(inputRange):\n",
    "    start,stop = inputRange.split(\" - \")\n",
    "    \n",
    "    ## assert that the start and stop are always\n",
    "    ## 3 characters long\n",
    "    assert len(start) == 3, inputRange\n",
    "    assert len(stop) == 3, inputRange\n",
    "    ## assert that the first two characters of\n",
    "    ## start and stop are always the same\n",
    "    assert start[:2] == stop[:2], inputRange\n",
    "    ## assert that the last character is always different\n",
    "    assert start[-1] != stop[-1], inputRange\n",
    "    \n",
    "    ## if the last characters are A and Z...\n",
    "    if (start[-1] == \"A\") and (stop[-1] == \"Z\"):\n",
    "        ## assume that we only need to check the first two characters\n",
    "        start = start[:-1]\n",
    "        stop = stop[:-1]\n",
    "        \n",
    "    ## well if all that is the case, then we\n",
    "    ## can easily build a regex, can't we?\n",
    "    invariant_prefix = start[:2]\n",
    "    variable_suffix_start = start[-1]\n",
    "    variable_suffix_end = stop[-1]\n",
    "    regex = f\"^{invariant_prefix}[{variable_suffix_start}-{variable_suffix_end}]\" if len(start) > 2 else f\"^{invariant_prefix}\"\n",
    "    \n",
    "    return regex\n",
    "\n",
    "def parseStartStop(inputString):\n",
    "    return inputString.split(\" - \")\n",
    "\n",
    "sub_df[\"regex\"] = sub_df[\"Series\"].apply(parse_into_regex)\n",
    "\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "## netherlands are badly behaved, fix that\n",
    "dupes_df = sub_df[sub_df.duplicated([\"Series\"], keep=False)]\n",
    "dupes_df = pd.concat([pd.DataFrame(\n",
    "        [(\" or \".join(list(temp_df[\"region\"])), regex)]\n",
    "    ) for regex, temp_df in dupes_df.groupby(\"regex\")]).rename({0: \"region\", 1: \"regex\"}, axis=1)\n",
    "\n",
    "dupes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = sub_df.drop_duplicates(\"Series\", keep=False).drop(\"Series\", axis=1)\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_records = []\n",
    "\n",
    "for round_dict in [first_round_dict, second_round_dict, third_round_dict]:\n",
    "    for k,v in round_dict.items():\n",
    "        regex_records.append((v, f\"^{k}\"))\n",
    "        \n",
    "final_regex_df = pd.concat([\n",
    "    pd.DataFrame(regex_records).rename({0: \"region\", 1: \"regex\"}, axis=1),\n",
    "    sub_df,\n",
    "    dupes_df\n",
    "])\n",
    "\n",
    "final_regex_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "callsign_ref_dict = {}\n",
    "\n",
    "for region, meta in final_regex_df.groupby(\"region\"):\n",
    "    callsign_ref_dict[region] = list(meta[\"regex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../res/callsign_ref.json\", \"w\") as outfile:\n",
    "    outfile.write(json.dumps(callsign_ref_dict, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
